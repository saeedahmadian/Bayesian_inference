{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "conda 4.7.5\r\n"
                }
            ], 
            "source": "! conda --version"
        }, 
        {
            "source": "## Beysian Inference\nIt is a method of inference where the probibility of a hypothesis is updated as new evidence becomes available\n### Steps\n\n** 1. Begin with a prior distribution processes : P(H)\n\n** 2. collect data to obtain the observed distribution P(E) as evidence\n\n** 3. calculate the likelihood of our observation given the hypothesis distribution (you can say we want to know how likely we can generate these observations data given aour hypothesis\ndistribution P(E|H))   \n\n** 4. obtain the posterior or simple update the prior which is the correct distribution for another unseen data) P(H|E)\n\n### bayes rule\n$$\nP(H|E) = \\frac{P(E|H) \\times P(H)}{p(E)} \n$$", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Maximum a posterior estimation\n\n**note : the likelihood of a given sample $x$ is calculated as $p(x|\\mu,\\sigma) = \\frac{1}{\\sqrt{(2\\pi \\sigma^{2})}} \\exp(-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}) $\n\n**example: we have two class of male and female and their height---> we can compute each class mean and std and then we can create our prior \n\n**now if given a new sample we can predict its class therefore we can do it for unseen samples\n\n**The problem is as \n\n$$\nClass = \\armax_{c \\in {c_{male},c_{female} } } P(c|x)\n$$\n\ntherefor using bayes Rule and theank to likelihood that we can compute $p(x|c)$ we can reformulate and write general expression\n\n$$\n\\max_{c\\in C} \\frac{p(x|c)\\times p(c)}{p(x)}\n$$\n\nHowever we don't have $p(x)$ because we haven't seen all the x yet and there are a lots of unseen $x$ yet, but if you see the optimization it is independent from x, or better to say \nthe probability distribution of data is independent from our classess because the data does not know and care about being male or female so we simply can forget about that in our optimization pronblem\n\n*So\n$\n\\max_{c\\in C} p(x|c)\\times p(c)\n$", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark", 
            "name": "python36", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}